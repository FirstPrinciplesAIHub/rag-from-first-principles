# RAG From First Principles

This repository is a **from-first-principles implementation of a production-grade Retrieval-Augmented Generation (RAG) system**.

The goal is **not** to glue tools together, but to deeply understand:
- why each layer exists
- what problem it solves
- where failures occur
- how correctness is enforced
- where responsibility stops

This system is **deliberately layered, audited, and fail-closed**.

---

## High-Level Flow (Mental Model)

```
User Query
   â†“
Day 04 â€” Retrieval â†’ Context (Judgment)
   â†“
Day 05 â€” Context â†’ Answer (Generation)
   â†“
Day 06 â€” Semantic Validation (Entailment)
   â†“
Day 07 â€” Claim â†” Citation Alignment
   â†“
Day 08 â€” Presentation & Exposure Control
   â†“
Day 09 â€” Observability (Decision Trace)
   â†“
Day 10 â€” Evaluation & Regression Detection
   â†“
Day 11 â€” CI Enforcement
   â†“
Day 12 â€” Production Hardening (Real LLM, Cost)
```

Each day introduces **exactly one responsibility**.  
No day leaks responsibility into another.

---

## Design Principles (Non-Negotiable)

- **Fail closed** â€” invalid answers are suppressed, never â€œbest effortâ€
- **LLM is untrusted** â€” correctness is enforced outside the model
- **Evidence first** â€” context is curated before generation
- **No silent behavior** â€” every decision is observable
- **Policy over code** â€” behavior changes via policy, not logic edits
- **Stop when complete** â€” no scope creep

---

## Day-by-Day Architecture

### Day 01 â€” RAG Mental Model
LLMs do not know your documents. Embeddings encode meaning as geometry. Retrieval finds relevant context, not answers.

### Day 02 â€” Document â†’ Chunks
Documents are split into atomic, single-idea chunks. Chunking errors cannot be fixed downstream.

### Day 03 â€” Chunks â†’ Embeddings â†’ Retrieval
Chunks are embedded and stored. Queries retrieve candidates via similarity search.

### Day 04 â€” Retrieval â†’ Context (Judgment Layer)
A strict judgment layer decides what evidence is admissible. The output is a `ContextPack`, the only object allowed to reach the LLM.

### Day 05 â€” Context â†’ Answer (Generation)
The LLM is a constrained generator. Answers must cite provided sources or are rejected.

### Day 06 â€” Semantic Validation
Every factual claim is checked for entailment against context. Any unsupported claim fails the answer.

### Day 07 â€” Claim â†” Citation Alignment
Ensures citations actually support the claims they reference.

### Day 08 â€” Presentation & Exposure Control
Decides whether an answer is shown, warned, or suppressedâ€”without modifying content.

### Day 09 â€” Observability
Every decision is recorded in an immutable decision trace for auditability.

### Day 10 â€” Evaluation & Regression Detection
Golden cases, confidence scoring, and regression detection prevent silent behavior drift.

### Day 11 â€” CI Enforcement
Blocking regressions fail CI automatically.

### Day 12 â€” Production Hardening
Real OpenAI LLM integration with token and cost tracking, without affecting behavior.

---

## Running the System

### Test mode
```
export RAG_ENV=test
pytest
```

### Production mode (OpenAI)
```
export RAG_ENV=prod
export OPENAI_API_KEY=sk-...
export OPENAI_MODEL=gpt-4.1-mini

python3 -m application.app
```

---

## Why This Project Stops Here

This system is architecturally complete. Anything beyond this point would be optimization or productization, not core design.

**Correctness first. Always.**


## ğŸ§  RAG From First Principles â€” Architecture

The diagram below shows the full end-to-end pipeline, from document ingestion
to production enforcement, built incrementally over Days 01â€“12.

![RAG From First Principles Architecture](docs/images/rag_architecture_diagram.png)